{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames: Read and Write Data\n",
    "     \n",
    "Dask Dataframes can read and store data in many of the same formats as Pandas dataframes.  In this example we read and write data with the popular CSV and Parquet formats, and discuss best practices when using these formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/travis/miniconda/envs/test/lib/python3.8/site-packages/IPython/core/display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0eEsIA0O1iE?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0eEsIA0O1iE?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Dask Client for Dashboard\n",
    "\n",
    "Starting the Dask Client is optional.  It will provide a dashboard which \n",
    "is useful to gain insight on the computation.  \n",
    "\n",
    "The link to the dashboard will become visible when you create the client below.  We recommend having it open on one side of your screen while using your notebook on the other side.  This can take some effort to arrange your windows, but seeing them both at the same is very useful when learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://10.20.255.13/10576/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.20.255.13:8787/status' target='_blank'>http://10.20.255.13:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>2.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://10.20.255.13/10576/1' processes=1 threads=4, memory=2.00 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=1, threads_per_worker=4, processes=False, memory_limit='2GB')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create artificial dataset\n",
    "\n",
    "First we create an artificial dataset and write it to many CSV files.\n",
    "\n",
    "You don't need to understand this section, we're just creating a dataset for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=30</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: make-timeseries, 30 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   id    name        x        y\n",
       "npartitions=30                                 \n",
       "2000-01-01      int64  object  float64  float64\n",
       "2000-01-02        ...     ...      ...      ...\n",
       "...               ...     ...      ...      ...\n",
       "2000-01-30        ...     ...      ...      ...\n",
       "2000-01-31        ...     ...      ...      ...\n",
       "Dask Name: make-timeseries, 30 tasks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "df = dask.datasets.timeseries()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "def name(i):\n",
    "    \"\"\" Provide date for filename given index\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> name(0)\n",
    "    '2000-01-01'\n",
    "    >>> name(10)\n",
    "    '2000-01-11'\n",
    "    \"\"\"\n",
    "    return str(datetime.date(2000, 1, 1) + i * datetime.timedelta(days=1))\n",
    "    \n",
    "df.to_csv('data/*.csv', name_function=name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV files\n",
    "\n",
    "We now have many CSV files in our data directory, one for each day in the month of January 2000.  Each CSV file holds timeseries data for that day.  We can read all of them as one logical dataframe using the `dd.read_csv` function with a glob string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/2000-01-01.csv\r\n",
      "data/2000-01-02.csv\r\n",
      "data/2000-01-03.csv\r\n",
      "data/2000-01-04.csv\r\n",
      "data/2000-01-05.csv\r\n",
      "data/2000-01-06.csv\r\n",
      "data/2000-01-07.csv\r\n",
      "data/2000-01-08.csv\r\n",
      "data/2000-01-09.csv\r\n",
      "data/2000-01-10.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/*.csv | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,id,name,x,y\r\n",
      "2000-01-01 00:00:00,1049,Kevin,0.9889387168849251,-0.18879907519645345\r\n",
      "2000-01-01 00:00:01,987,Zelda,0.18435140106734704,0.22328546191503462\r\n",
      "2000-01-01 00:00:02,1032,Oliver,-0.8656486136303023,-0.84347660766973\r\n",
      "2000-01-01 00:00:03,985,George,0.1531226882077772,0.8129151716586236\r\n",
      "2000-01-01 00:00:04,999,Ingrid,0.6381471974881376,-0.03373012435495837\r\n",
      "2000-01-01 00:00:05,1035,Tim,0.7300453791495161,0.6402288571435129\r\n",
      "2000-01-01 00:00:06,1027,Kevin,-0.8761155539185899,-0.6234723158090154\r\n",
      "2000-01-01 00:00:07,1031,Kevin,0.4603115993580653,-0.34967382626203114\r\n",
      "2000-01-01 00:00:08,1031,George,-0.45683736345572634,-0.5874202378045148\r\n"
     ]
    }
   ],
   "source": [
    "!head data/2000-01-01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp,id,name,x,y\r\n",
      "2000-01-30 00:00:00,1062,Zelda,-0.0102339469344217,-0.5690278182545085\r\n",
      "2000-01-30 00:00:01,935,Victor,0.1151823769590572,0.6024583797219896\r\n",
      "2000-01-30 00:00:02,994,Dan,-0.8864102911848004,-0.9999383764723666\r\n",
      "2000-01-30 00:00:03,961,Edith,0.5748144180731933,0.6834480724465504\r\n",
      "2000-01-30 00:00:04,1029,Ingrid,0.6147553212554586,0.5790933853868752\r\n",
      "2000-01-30 00:00:05,1010,Yvonne,0.05119278174257258,-0.8951626316990005\r\n",
      "2000-01-30 00:00:06,968,Jerry,-0.9600717751495635,-0.269244543073347\r\n",
      "2000-01-30 00:00:07,1040,Quinn,0.3163826788626056,-0.9175325840279289\r\n",
      "2000-01-30 00:00:08,943,Zelda,-0.8013483162148571,0.03132276471432305\r\n"
     ]
    }
   ],
   "source": [
    "!head data/2000-01-30.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read one file with `pandas.read_csv` or many files with `dask.dataframe.read_csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>1049</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>-0.188799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 00:00:01</td>\n",
       "      <td>987</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>0.184351</td>\n",
       "      <td>0.223285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01 00:00:02</td>\n",
       "      <td>1032</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>-0.865649</td>\n",
       "      <td>-0.843477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01 00:00:03</td>\n",
       "      <td>985</td>\n",
       "      <td>George</td>\n",
       "      <td>0.153123</td>\n",
       "      <td>0.812915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01 00:00:04</td>\n",
       "      <td>999</td>\n",
       "      <td>Ingrid</td>\n",
       "      <td>0.638147</td>\n",
       "      <td>-0.033730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    id    name         x         y\n",
       "0  2000-01-01 00:00:00  1049   Kevin  0.988939 -0.188799\n",
       "1  2000-01-01 00:00:01   987   Zelda  0.184351  0.223285\n",
       "2  2000-01-01 00:00:02  1032  Oliver -0.865649 -0.843477\n",
       "3  2000-01-01 00:00:03   985  George  0.153123  0.812915\n",
       "4  2000-01-01 00:00:04   999  Ingrid  0.638147 -0.033730"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/2000-01-01.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=30</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 30 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               timestamp     id    name        x        y\n",
       "npartitions=30                                           \n",
       "                  object  int64  object  float64  float64\n",
       "                     ...    ...     ...      ...      ...\n",
       "...                  ...    ...     ...      ...      ...\n",
       "                     ...    ...     ...      ...      ...\n",
       "                     ...    ...     ...      ...      ...\n",
       "Dask Name: read-csv, 30 tasks"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('data/2000-*-*.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:00:00</td>\n",
       "      <td>1049</td>\n",
       "      <td>Kevin</td>\n",
       "      <td>0.988939</td>\n",
       "      <td>-0.188799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 00:00:01</td>\n",
       "      <td>987</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>0.184351</td>\n",
       "      <td>0.223285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01 00:00:02</td>\n",
       "      <td>1032</td>\n",
       "      <td>Oliver</td>\n",
       "      <td>-0.865649</td>\n",
       "      <td>-0.843477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01 00:00:03</td>\n",
       "      <td>985</td>\n",
       "      <td>George</td>\n",
       "      <td>0.153123</td>\n",
       "      <td>0.812915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01 00:00:04</td>\n",
       "      <td>999</td>\n",
       "      <td>Ingrid</td>\n",
       "      <td>0.638147</td>\n",
       "      <td>-0.033730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    id    name         x         y\n",
       "0  2000-01-01 00:00:00  1049   Kevin  0.988939 -0.188799\n",
       "1  2000-01-01 00:00:01   987   Zelda  0.184351  0.223285\n",
       "2  2000-01-01 00:00:02  1032  Oliver -0.865649 -0.843477\n",
       "3  2000-01-01 00:00:03   985  George  0.153123  0.812915\n",
       "4  2000-01-01 00:00:04   999  Ingrid  0.638147 -0.033730"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning read_csv\n",
    "\n",
    "The Pandas `read_csv` function has *many* options to help you parse files.  The Dask version uses the Pandas function internally, and so supports many of the same options.  You can use the `?` operator to see the full documentation string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we use the `parse_dates` keyword to parse the timestamp column to be a datetime.  This will make things more efficient in the future.  Notice that the dtype of the timestamp column has changed from `object` to `datetime64[ns]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=30</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 30 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                     timestamp     id    name        x        y\n",
       "npartitions=30                                                 \n",
       "                datetime64[ns]  int64  object  float64  float64\n",
       "                           ...    ...     ...      ...      ...\n",
       "...                        ...    ...     ...      ...      ...\n",
       "                           ...    ...     ...      ...      ...\n",
       "                           ...    ...     ...      ...      ...\n",
       "Dask Name: read-csv, 30 tasks"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_csv('data/2000-*-*.csv', parse_dates=['timestamp'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a simple computation\n",
    "\n",
    "Whenever we operate on our dataframe we read through all of our CSV data so that we don't fill up RAM.  This is very efficient for memory use, but reading through all of the CSV files every time can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 715 ms, total: 5.37 s\n",
      "Wall time: 3.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "Alice      -0.001492\n",
       "Bob        -0.000668\n",
       "Charlie     0.001509\n",
       "Dan        -0.001079\n",
       "Edith       0.003000\n",
       "Frank      -0.000993\n",
       "George      0.000419\n",
       "Hannah     -0.000839\n",
       "Ingrid      0.000143\n",
       "Jerry      -0.000085\n",
       "Kevin       0.000847\n",
       "Laura       0.000973\n",
       "Michael    -0.000197\n",
       "Norbert    -0.001075\n",
       "Oliver      0.001497\n",
       "Patricia   -0.001590\n",
       "Quinn      -0.000893\n",
       "Ray         0.003605\n",
       "Sarah      -0.001304\n",
       "Tim        -0.000583\n",
       "Ursula     -0.000104\n",
       "Victor      0.000354\n",
       "Wendy       0.000324\n",
       "Xavier      0.000493\n",
       "Yvonne      0.002818\n",
       "Zelda       0.002040\n",
       "Name: x, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.groupby('name').x.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Parquet\n",
    "\n",
    "Instead, we'll store our data in Parquet, a format that is more efficient for computers to read and write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('data/2000-01.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_common_metadata  part.15.parquet  part.22.parquet  part.2.parquet\r\n",
      "_metadata\t  part.16.parquet  part.23.parquet  part.3.parquet\r\n",
      "part.0.parquet\t  part.17.parquet  part.24.parquet  part.4.parquet\r\n",
      "part.10.parquet   part.18.parquet  part.25.parquet  part.5.parquet\r\n",
      "part.11.parquet   part.19.parquet  part.26.parquet  part.6.parquet\r\n",
      "part.12.parquet   part.1.parquet   part.27.parquet  part.7.parquet\r\n",
      "part.13.parquet   part.20.parquet  part.28.parquet  part.8.parquet\r\n",
      "part.14.parquet   part.21.parquet  part.29.parquet  part.9.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/2000-01.parquet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=30</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-parquet, 30 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                     timestamp     id    name        x        y\n",
       "npartitions=30                                                 \n",
       "                datetime64[ns]  int64  object  float64  float64\n",
       "                           ...    ...     ...      ...      ...\n",
       "...                        ...    ...     ...      ...      ...\n",
       "                           ...    ...     ...      ...      ...\n",
       "                           ...    ...     ...      ...      ...\n",
       "Dask Name: read-parquet, 30 tasks"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_parquet('data/2000-01.parquet', engine='pyarrow')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 156 ms, total: 1.66 s\n",
      "Wall time: 1.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "Alice      -0.001492\n",
       "Bob        -0.000668\n",
       "Charlie     0.001509\n",
       "Dan        -0.001079\n",
       "Edith       0.003000\n",
       "Frank      -0.000993\n",
       "George      0.000419\n",
       "Hannah     -0.000839\n",
       "Ingrid      0.000143\n",
       "Jerry      -0.000085\n",
       "Kevin       0.000847\n",
       "Laura       0.000973\n",
       "Michael    -0.000197\n",
       "Norbert    -0.001075\n",
       "Oliver      0.001497\n",
       "Patricia   -0.001590\n",
       "Quinn      -0.000893\n",
       "Ray         0.003605\n",
       "Sarah      -0.001304\n",
       "Tim        -0.000583\n",
       "Ursula     -0.000104\n",
       "Victor      0.000354\n",
       "Wendy       0.000324\n",
       "Xavier      0.000493\n",
       "Yvonne      0.002818\n",
       "Zelda       0.002040\n",
       "Name: x, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.groupby('name').x.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only the columns that you plan to use\n",
    "\n",
    "Parquet is a column-store, which means that it can efficiently pull out only a few columns from your dataset.  This is good because it helps to avoid unnecessary data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 58.2 ms, total: 1.48 s\n",
      "Wall time: 1.08 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name\n",
       "Alice      -0.001492\n",
       "Bob        -0.000668\n",
       "Charlie     0.001509\n",
       "Dan        -0.001079\n",
       "Edith       0.003000\n",
       "Frank      -0.000993\n",
       "George      0.000419\n",
       "Hannah     -0.000839\n",
       "Ingrid      0.000143\n",
       "Jerry      -0.000085\n",
       "Kevin       0.000847\n",
       "Laura       0.000973\n",
       "Michael    -0.000197\n",
       "Norbert    -0.001075\n",
       "Oliver      0.001497\n",
       "Patricia   -0.001590\n",
       "Quinn      -0.000893\n",
       "Ray         0.003605\n",
       "Sarah      -0.001304\n",
       "Tim        -0.000583\n",
       "Ursula     -0.000104\n",
       "Victor      0.000354\n",
       "Wendy       0.000324\n",
       "Xavier      0.000493\n",
       "Yvonne      0.002818\n",
       "Zelda       0.002040\n",
       "Name: x, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = dd.read_parquet('data/2000-01.parquet', columns=['name', 'x'], engine='pyarrow')\n",
    "df.groupby('name').x.mean().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the difference is not that large, but with larger datasets this can save a great deal of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "\n",
    "http://dask.pydata.org/en/latest/dataframe-create.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
