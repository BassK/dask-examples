{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automate Machine Learning with TPOT\n",
    "===================================\n",
    "\n",
    "This example shows how [TPOT](https://epistasislab.github.io/tpot/) can be used with Dask.\n",
    "\n",
    "TPOT is an [automated machine learning](https://en.wikipedia.org/wiki/Automated_machine_learning) library.\n",
    "It evaluates many scikit-learn pipelines and hyperparameter combinations to find a model that works well for your data. Evaluating all these computations is computationally expensive, but ammenable to parallelism. TPOT can use Dask to distribute these computations on a cluster of machines.\n",
    "\n",
    "This notebook can be run interactively on the [dask examples binder](https://github.com/dask/dask-examples).\n",
    "The following video shows a larger version of this notebook on a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"position:relative;height:0;padding-bottom:56.25%\"><iframe src=\"https://www.youtube.com/embed/uyx9nBuOYQQ?ecver=2\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" style=\"position:absolute;width:100%;height:100%;left:0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<div style=\"position:relative;height:0;padding-bottom:56.25%\"><iframe src=\"https://www.youtube.com/embed/uyx9nBuOYQQ?ecver=2\" width=\"640\" height=\"360\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" style=\"position:absolute;width:100%;height:100%;left:0\" allowfullscreen></iframe></div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tpot\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading TPOT-0.11.5-py3-none-any.whl (82 kB)\r\n",
      "\u001b[?25l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.3 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from tpot) (1.17.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stopit>=1.1.1\r\n",
      "  Downloading stopit-1.1.2.tar.gz (18 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib>=0.13.2 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from tpot) (0.16.0)\r\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from tpot) (4.47.0)\r\n",
      "Requirement already satisfied: scipy>=1.3.1 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from tpot) (1.5.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting update-checker>=0.16\r\n",
      "  Downloading update_checker-0.17-py2.py3-none-any.whl (7.0 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=0.24.2 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from tpot) (0.25.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deap>=1.2\r\n",
      "  Downloading deap-1.3.1-cp37-cp37m-manylinux2010_x86_64.whl (157 kB)\r\n",
      "\u001b[?25l"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.0 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from tpot) (0.22.2.post1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests>=2.3.0 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from update-checker>=0.16->tpot) (2.24.0)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from pandas>=0.24.2->tpot) (2020.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from pandas>=0.24.2->tpot) (2.8.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.6.20)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.25.9)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/travis/miniconda/envs/test/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->tpot) (1.15.0)\r\n",
      "Building wheels for collected packages: stopit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for stopit (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Created wheel for stopit: filename=stopit-1.1.2-py3-none-any.whl size=11956 sha256=f8ef98f905961d8d6cc82256a18fba4c3a6ff884c1f6e2a21f5f3ea0e0134241\r\n",
      "  Stored in directory: /home/travis/.cache/pip/wheels/e2/d2/79/eaf81edb391e27c87f51b8ef901ecc85a5363dc96b8b8d71e3\r\n",
      "Successfully built stopit\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: stopit, update-checker, deap, tpot\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed deap-1.3.1 stopit-1.1.2 tpot-0.11.5 update-checker-0.17\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/travis/miniconda/envs/test/lib/python3.7/site-packages/tpot/builtins/__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    }
   ],
   "source": [
    "import tpot\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dask\n",
    "\n",
    "We first start a Dask client in order to get access to the Dask dashboard, which will provide progress and performance metrics. \n",
    "\n",
    "You can view the dashboard by clicking on the dashboard link after you run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:40945</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>8.36 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:40945' processes=4 threads=4, memory=8.36 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client(n_workers=4, threads_per_worker=1)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data\n",
    "\n",
    "We'll use the digits dataset.\n",
    "To ensure the example runs quickly, we'll make the training dataset relatively small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data,\n",
    "    digits.target,\n",
    "    train_size=0.05,\n",
    "    test_size=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are just small, in-memory NumPy arrays. This example is not applicable to larger-than-memory Dask arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dask\n",
    "\n",
    "TPOT follows the scikit-learn API; we specify a `TPOTClassifier` with a few hyperparameters, and then fit it on some data.\n",
    "By default, TPOT trains on your single machine.\n",
    "To ensure your cluster is used, specify the `use_dask` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale up: Increase the TPOT parameters like population_size, generations\n",
    "tp = TPOTClassifier(\n",
    "    generations=2,\n",
    "    population_size=10,\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=0,\n",
    "    verbosity=0,\n",
    "    config_dict=tpot.config.classifier_config_dict_light,\n",
    "    use_dask=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict={'sklearn.cluster.FeatureAgglomeration': {'affinity': ['euclidean',\n",
       "                                                                                  'l1',\n",
       "                                                                                  'l2',\n",
       "                                                                                  'manhattan',\n",
       "                                                                                  'cosine'],\n",
       "                                                                     'linkage': ['ward',\n",
       "                                                                                 'complete',\n",
       "                                                                                 'average']},\n",
       "                            'sklearn.decomposition.PCA': {'iterated_power': range(1, 11),\n",
       "                                                          'svd_solver': ['randomized']},\n",
       "                            'sklearn.feature_selection.SelectFwe': {'alpha': array([0.   , 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007...\n",
       "               crossover_rate=0.1, cv=2, disable_update_check=False,\n",
       "               early_stop=None, generations=2,\n",
       "               log_file=<ipykernel.iostream.OutStream object at 0x7f02672c5e50>,\n",
       "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "               mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
       "               periodic_checkpoint_folder=None, population_size=10,\n",
       "               random_state=0, scoring=None, subsample=1.0, template=None,\n",
       "               use_dask=True, verbosity=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn More\n",
    "\n",
    "See the [Dask-ML](http://ml.dask.org/) and [TPOT](https://epistasislab.github.io/tpot/) documenation for more information on using Dask and TPOT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
