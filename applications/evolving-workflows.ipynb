{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle Evolving Workflows\n",
    "=========================\n",
    "\n",
    "For some workflows we don't know the extent of the computation at the outset.  We need to do some computation in order to figure out the rest of the computation that we need to do.  The computation grows and evolves as we do more work.\n",
    "\n",
    "As an example, consider a situation where you need to read many files and then based on the contents of those files, fire off additional work.  You would like to read the files in parallel, and then within each file expose more parallelism.\n",
    "\n",
    "This example goes through three ways to handle this situation using [Dask Futures](https://docs.dask.org/en/latest/futures.html)\n",
    "\n",
    "1.  Using `as_completed`\n",
    "2.  Using `async/await`\n",
    "3.  Launching tasks from tasks\n",
    "\n",
    "But first, lets run our code sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: Sequential code\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file.0.txt', 'file.1.txt', 'file.2.txt']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [\"file.{}.txt\".format(i) for i in range(10)]\n",
    "\n",
    "filenames[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time\n",
    "\n",
    "\n",
    "def parse_file(fn: str) -> list:\n",
    "    \"\"\" Returns a list work items of unknown length \"\"\"\n",
    "    time.sleep(random.random())\n",
    "    return [random.random() for _ in range(random.randint(1, 10))]\n",
    "\n",
    "def process_item(x: float):\n",
    "    \"\"\" Process each work item \"\"\"\n",
    "    time.sleep(random.random() / 4)\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 657 Âµs, sys: 3.97 ms, total: 4.63 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# This takes around 10-20s\n",
    "\n",
    "results = []\n",
    "\n",
    "for fn in filenames:\n",
    "    L = parse_file(fn)\n",
    "    for x in L:\n",
    "        out = process_item(x)\n",
    "        results.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Dask Client\n",
    "-----------------\n",
    "\n",
    "We'll need a Dask client in order to manage dynamic workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://10.20.255.13/8341/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.20.255.13:8787/status' target='_blank'>http://10.20.255.13:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>8.36 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://10.20.255.13/8341/1' processes=1 threads=6, memory=8.36 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(processes=False, n_workers=1, threads_per_worker=6)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Use as_completed\n",
    "-------------------\n",
    "\n",
    "The [as_completed](https://docs.dask.org/en/latest/futures.html#distributed.as_completed) iterator lets us handle futures as they complete.  We can then submit more data on the fly.\n",
    "\n",
    "-   We submit a task for each of our filenames\n",
    "-   We also compute the length of each of the returned lists\n",
    "-   As those lengths return, we submit off a new task to get each item of that list.  We do this at higher priority, so that we process existing data before we collect new data.\n",
    "-   We wait on all of the returned results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 287 ms, sys: 45 ms, total: 332 ms\n",
      "Wall time: 2.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6286041937471265,\n",
       " 1.6668582134467644,\n",
       " 1.0987198295673735,\n",
       " 1.3025401327283723,\n",
       " 1.0391991965008218,\n",
       " 1.9578228056358071,\n",
       " 1.3308025699015953,\n",
       " 1.844582143015287,\n",
       " 1.365642380031004,\n",
       " 1.5560770865333837,\n",
       " 1.9552625792590952,\n",
       " 1.9584115452177198,\n",
       " 1.5087767813166657,\n",
       " 1.4764895978516805,\n",
       " 1.1436908540244068,\n",
       " 1.0745396717029054,\n",
       " 1.75085656427805,\n",
       " 1.766930583618601,\n",
       " 1.6300257563278957,\n",
       " 1.533979215649116,\n",
       " 1.1208043478470406,\n",
       " 1.7304708514016953,\n",
       " 1.24752831320758,\n",
       " 1.1400447514196725,\n",
       " 1.6510737399642763,\n",
       " 1.9482181573429223,\n",
       " 1.4013051175051694,\n",
       " 1.8190621546259151,\n",
       " 1.9349411687997715,\n",
       " 1.3130275057496508,\n",
       " 1.7788370620992238,\n",
       " 1.4834034919176298,\n",
       " 1.1707790845098471,\n",
       " 1.341316850826162,\n",
       " 1.2979950582584054,\n",
       " 1.475181061903637,\n",
       " 1.3509376004304199,\n",
       " 1.8234898378230096,\n",
       " 1.0256651014086486,\n",
       " 1.5852890596932179,\n",
       " 1.0887329529813936,\n",
       " 1.6333873816768656,\n",
       " 1.886987753725629,\n",
       " 1.3574735585617197,\n",
       " 1.4023819285722747,\n",
       " 1.2465593739428589,\n",
       " 1.7566062411213388,\n",
       " 1.1766058220353397,\n",
       " 1.4610778545017855,\n",
       " 1.3027096651302101,\n",
       " 1.3920043188849638,\n",
       " 1.9404177688521203,\n",
       " 1.152848094150393]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dask.distributed import as_completed\n",
    "import operator\n",
    "\n",
    "lists = client.map(parse_file, filenames, pure=False)\n",
    "lengths = client.map(len, lists)\n",
    "\n",
    "mapping = dict(zip(lengths, lists))\n",
    "\n",
    "futures = []\n",
    "\n",
    "for future in as_completed(lengths):\n",
    "    n = future.result()\n",
    "    L = mapping[future]\n",
    "    for i in range(n):\n",
    "        new = client.submit(operator.getitem, L, i, priority=1)\n",
    "        new = client.submit(process_item, new, priority=1)\n",
    "        futures.append(new)\n",
    "        \n",
    "client.gather(futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Use async/await to handle single file processing locally\n",
    "-----------------------------------------------------------\n",
    "\n",
    "We can also handle the concurrency here within our local process.  This requires you to understand async/await syntax, but is generally powerful and arguably simpler than the `as_completed` approach above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def f(fn):\n",
    "    \"\"\" Handle the lifecycle of a single file \"\"\"\n",
    "    future = client.submit(parse_file, fn, pure=False)\n",
    "    length_future = client.submit(len, future)\n",
    "    length = await length_future\n",
    "    \n",
    "    futures = [client.submit(operator.getitem, future, i, priority=10) \n",
    "               for i in range(length)]\n",
    "    futures = client.map(process_item, futures, priority=10)\n",
    "    return futures\n",
    "\n",
    "async def run_all(filenames):\n",
    "    list_of_list_of_futures = await asyncio.gather(*[f(fn) for fn in filenames])\n",
    "    futures = sum(list_of_list_of_futures, [])\n",
    "    return await client.gather(futures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to run this function in the same event loop as our client is running.  If we had started our client asynchronously, then we could have done this:\n",
    "\n",
    "```python\n",
    "client = await Client(asynchronous=True)\n",
    "\n",
    "await run_all(filenames)\n",
    "```\n",
    "\n",
    "However, because we started our client without the `asynchronous=True` flag the event loop is actually running in a separate thread, so we'll have to ask the client to run this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.8401813096369732,\n",
       " 1.4951067255114032,\n",
       " 1.7168526520950462,\n",
       " 1.420430742687571,\n",
       " 1.1483000137753963,\n",
       " 1.9544161657090071,\n",
       " 1.16255549718553,\n",
       " 1.6203949238601543,\n",
       " 1.6828210310075784,\n",
       " 1.4504573241695047,\n",
       " 1.9037897279315508,\n",
       " 1.8754642794527556,\n",
       " 1.8458684087661976,\n",
       " 1.653407040911301,\n",
       " 1.6067605575198507,\n",
       " 1.205863562987298,\n",
       " 1.9828747902384083,\n",
       " 1.1650949269724582,\n",
       " 1.6039505606680735,\n",
       " 1.36410938425852,\n",
       " 1.2882422260547006,\n",
       " 1.8004522357017672,\n",
       " 1.0420794261770268,\n",
       " 1.614077766194281,\n",
       " 1.6926492259005133,\n",
       " 1.259636654409909,\n",
       " 1.6777758874374058,\n",
       " 1.9628286310245535,\n",
       " 1.1946679062099022,\n",
       " 1.0505049857942392,\n",
       " 1.7663402647494104,\n",
       " 1.4885600525936116,\n",
       " 1.8642022653944084,\n",
       " 1.223633365590958,\n",
       " 1.9025970083713568,\n",
       " 1.917619007312168,\n",
       " 1.6891883902657094,\n",
       " 1.2119664021980103,\n",
       " 1.2545728139748629,\n",
       " 1.9538440247263549,\n",
       " 1.722279411472793,\n",
       " 1.8919317180119641,\n",
       " 1.2717453183688916,\n",
       " 1.5244895928227677,\n",
       " 1.249621171896835,\n",
       " 1.4357228090654441,\n",
       " 1.5665888055127417,\n",
       " 1.0638112937797524,\n",
       " 1.3591755004216215,\n",
       " 1.5405883962632747,\n",
       " 1.8528406114556504,\n",
       " 1.9232229070607578,\n",
       " 1.6078875082060056,\n",
       " 1.3855016471863553,\n",
       " 1.179496054199117,\n",
       " 1.0524120858374135,\n",
       " 1.384357782177835]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.sync(run_all, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3: Submit tasks from tasks\n",
    "--------------------------\n",
    "\n",
    "We can also submit tasks that themselves submit more tasks.  See [documentation here](https://docs.dask.org/en/latest/futures.html#submit-tasks-from-tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 249 ms, sys: 34.8 ms, total: 284 ms\n",
      "Wall time: 2.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dask.distributed import get_client, secede, rejoin\n",
    "\n",
    "def f(fn):\n",
    "    L = parse_file(fn)\n",
    "    client = get_client()\n",
    "    \n",
    "    futures = client.map(process_item, L, priority=10)\n",
    "    secede()\n",
    "    results = client.gather(futures)\n",
    "    rejoin()\n",
    "    return results\n",
    "\n",
    "futures = client.map(f, filenames, pure=False)\n",
    "results = client.gather(futures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
